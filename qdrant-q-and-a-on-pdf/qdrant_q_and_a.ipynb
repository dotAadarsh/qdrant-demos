{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install qdrant_client\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pK_ycMjS9zY",
        "outputId": "e3054bfb-4d12-4684-d5cf-c62de8ed8a38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.0.5-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.14.0\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.0.0,>=1.26.14 in /usr/local/lib/python3.9/dist-packages (from qdrant_client) (1.26.14)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.9/dist-packages (from qdrant_client) (1.51.3)\n",
            "Collecting grpcio-tools>=1.41.0\n",
            "  Downloading grpcio_tools-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.8 in /usr/local/lib/python3.9/dist-packages (from qdrant_client) (1.10.6)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from qdrant_client) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from qdrant_client) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (57.4.0)\n",
            "Collecting protobuf<5.0dev,>=4.21.6\n",
            "  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx[http2]>=0.14.0->qdrant_client) (2022.12.7)\n",
            "Collecting h2<5,>=3\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx[http2]>=0.14.0->qdrant_client) (2.10)\n",
            "Installing collected packages: rfc3986, sniffio, protobuf, hyperframe, hpack, h11, h2, grpcio-tools, anyio, httpcore, httpx, qdrant_client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.22.1 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.22.1 which is incompatible.\n",
            "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-3.6.2 grpcio-tools-1.51.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.16.3 httpx-0.23.3 hyperframe-6.0.1 protobuf-4.22.1 qdrant_client-1.0.5 rfc3986-1.5.0 sniffio-1.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Collecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2N6gdHrVSjjv"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "from qdrant_client.http import models\n",
        "import openai\n",
        "openai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client = QdrantClient(\n",
        "    host=\"<HOSTNAME>\",\n",
        "    api_key=\"<API_KEY>\",\n",
        ")"
      ],
      "metadata": {
        "id": "eauVwSDBS1RV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client.recreate_collection(\n",
        "    collection_name=\"mycollection\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
        ")\n",
        "print(\"Create collection reponse:\", qdrant_client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBgSvqfvTbOz",
        "outputId": "dc317571-876e-42d1-fe76-0a0d44afe864"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create collection reponse: <qdrant_client.qdrant_client.QdrantClient object at 0x7efbf0a310a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection_info = qdrant_client.get_collection(collection_name=\"mycollection\")\n",
        "\n",
        "print(\"Collection info:\", collection_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njOgvHcdT2Fr",
        "outputId": "0527b862-dc6a-4d13-a3f1-4450071c6856"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=0 indexed_vectors_count=0 points_count=0 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=True), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0)) payload_schema={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "vQ0nWIm3T8Hd",
        "outputId": "c82e6241-92bb-48e6-b0a2-0040671e8517"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Wand>=0.6.10\n",
            "  Downloading Wand-0.6.11-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.1\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=36.0.0\n",
            "  Downloading cryptography-39.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: Wand, Pillow, cryptography, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed Pillow-9.4.0 Wand-0.6.11 cryptography-39.0.2 pdfminer.six-20221105 pdfplumber-0.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "fulltext = \"\"\n",
        "with pdfplumber.open(\"/content/semantic_web.pdf\") as pdf:\n",
        "    # loop over all the pages\n",
        "    for page in pdf.pages:\n",
        "        fulltext += page.extract_text()\n",
        "\n",
        "print(fulltext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HWtz7W1T6Ay",
        "outputId": "91c8e785-f744-4b1c-a71d-7af31dd43b84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic web\n",
            "1. Introduction\n",
            "The Semantic Web is an extension of the World Wide Web through standards by the World\n",
            "Wide Web Consortium (W3C). Semantic Web standards enable the next generation of online\n",
            "data, giving users more control over how data is displayed and processed.\n",
            "The Semantic Web is built on the idea that computers can understand the meaning of information\n",
            "on the web (semantics) as well as the traditional meaning of structured data, like databases. This\n",
            "enables computers to automatically process and combine data in ways that humans can\n",
            "understand, making the Semantic Web a \" web of data \".\n",
            "2. What does semantic web mean?\n",
            "Let's separate the word. So first, what does semantics mean? To be specific, the word semantic\n",
            "means relating to meaning in language or logic .\n",
            "And we all know what does web mean right?. Web is short for World Wide Web. The World\n",
            "Wide Web is a network of online content that is accessible through the Internet. It includes\n",
            "websites, webpages, and other online resources.\n",
            "So combining these two’s we will be able to create a meaningful, insightful, data-driven web for\n",
            "the people.\n",
            "2. Why do we go for semantic web?\n",
            "There are a few reasons for why we might go for a semantic web. One reason is that it can help\n",
            "machines to better understand the data that is on the web, which can make it easier for them to\n",
            "find the information that we are looking for. Additionally, a semantic web can help to improve\n",
            "the way that search engines work, as they will be able to better understand the relationships\n",
            "between different pieces of information. Finally, it can make it easier for people to find the\n",
            "information they are looking for, as the semantic web can provide a way to organize information\n",
            "in a more logical way.\n",
            "13. Semantic web stack\n",
            "The Semantic Web stack includes standards for:\n",
            "- Interlinking data (URI, RDF, OWL)\n",
            "- Describing data (RDFS, OWL)\n",
            "- Query languages (SPARQL)\n",
            "- Serialization formats (RDF/XML, Turtle, JSON-LD)\n",
            "The Semantic Web is a stack of technologies that enables machines to understand the meaning of\n",
            "data on the web.\n",
            "- RDF : A data model for representing information as a graph of interconnected resources.\n",
            "- RDFS : A language for describing the types of resources in an RDF graph.\n",
            "- OWL : A language for expressing more complex relationships b/w resources in an RDF graph.\n",
            "- SPARQL : A query language for retrieving information from an RDF graph.\n",
            "Fig 1.1 Semantic web stack - user:Marobi1, CC0, via Wikimedia Commons\n",
            "4. Challenges\n",
            "There are a number of challenges associated with implementing the Semantic Web, including:\n",
            "21. Ensuring data quality and consistency : One of the challenges with implementing the\n",
            "Semantic Web is ensuring that the data being used is of high quality and is consistent across\n",
            "different sources. This can be a challenge because it requires organizations to agree on standards\n",
            "for how data should be structured and formatted.\n",
            "2. Interoperability : Another challenge with implementing the Semantic Web is ensuring\n",
            "interoperability between different systems. This can be a challenge because different systems\n",
            "may use different standards for how data is structured and formatted.\n",
            "3. Scalability : A third challenge with implementing the Semantic Web is ensuring that the\n",
            "system can scale to handle large amounts of data. This can be a challenge because the Semantic\n",
            "Web relies on ontologies, which can become very large and complex as the amount of data\n",
            "increases.\n",
            "4. Security and Privacy : A fourth challenge with implementing the Semantic Web is ensuring\n",
            "security and privacy. This can be a challenge because the Semantic Web relies on sharing data\n",
            "between different organizations, which can put sensitive information at risk.\n",
            "5. Cost : A final challenge with implementing the Semantic Web is the cost. This can be a\n",
            "challenge because the Semantic Web requires organizations to invest in new hardware and\n",
            "software, and to train staff on how to use the new system.\n",
            "5. Use cases of semantic web\n",
            "The goal of the Semantic Web is to make data on the web more machine-readable and easier to\n",
            "process. This enables new applications that can make use of this data, such as:\n",
            "- Automated data processing\n",
            "- Intelligent search\n",
            "- Personalized content\n",
            "- Semantic analytics\n",
            "The Semantic Web can be used for a variety of tasks, including:\n",
            "1. Finding and sharing information :\n",
            "3The Semantic Web can help you find the information you need, and also share the information\n",
            "you have.\n",
            "2. Connecting people and devices :\n",
            "The Semantic Web can connect people and devices, so that they can work together.\n",
            "3. Automating tasks :\n",
            "The Semantic Web can automate tasks, so that you can do more with less effort.\n",
            "4. Enhancing security :\n",
            "The Semantic Web can help to enhance security, by making it easier to identify and trust the\n",
            "sources of information.\n",
            "6. Researches\n",
            "Semantic Web can help to enhance security, by making it easier to identify and trust the sources\n",
            "of information. The ACACIA team of INRIA-Sophia-Antipolis, established in 2002, was the\n",
            "first research organization specifically devoted to the Corporate Semantic Web. The Corese\n",
            "search engine, which is RDF(S) based, is a result of their work, as is the use of semantic web\n",
            "technologies for knowledge management (such as ontologies and multi-agent systems for\n",
            "corporate semantic Web) and e-learning.\n",
            "The Free University of Berlin's Corporate Semantic Web research group has been concentrating\n",
            "on three building blocks since 2008: Corporate Semantic Search, Corporate Semantic\n",
            "Collaboration, and Corporate Ontology Engineering.\n",
            "The issue of how to integrate non-expert users in the creation of ontologies and semantically\n",
            "annotated content and for extracting explicit knowledge from user interaction within companies\n",
            "is one that is covered by ontology engineering research.\n",
            "7. CONCLUSION\n",
            "The Semantic Web is not a single technology or application. It is a collection of standards that\n",
            "can be used together to create data-driven applications. The Semantic Web is an important\n",
            "4concept that can help make information on the Internet more accessible and easier to use. By\n",
            "using Semantic Web technologies, information can be better organized and presented in a way\n",
            "that is easier for people to find and use.\n",
            "8. References\n",
            "1. Semantic Web ↗\n",
            "2. Semantic Web: A Review Of The Field ↗\n",
            "3. A semantic web technology index ↗\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = fulltext\n",
        "\n",
        "chunks = []\n",
        "while len(text) > 500:\n",
        "    last_period_index = text[:500].rfind('.')\n",
        "    if last_period_index == -1:\n",
        "        last_period_index = 500\n",
        "    chunks.append(text[:last_period_index])\n",
        "    text = text[last_period_index+1:]\n",
        "chunks.append(text)\n",
        "\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(chunk)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipVi0wHzVvN6",
        "outputId": "58e8b0ac-7b9e-4fd3-958a-c37608cca4e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic web\n",
            "1. Introduction\n",
            "The Semantic Web is an extension of the World Wide Web through standards by the World\n",
            "Wide Web Consortium (W3C). Semantic Web standards enable the next generation of online\n",
            "data, giving users more control over how data is displayed and processed.\n",
            "The Semantic Web is built on the idea that computers can understand the meaning of information\n",
            "on the web (semantics) as well as the traditional meaning of structured data, like databases\n",
            "---\n",
            " This\n",
            "enables computers to automatically process and combine data in ways that humans can\n",
            "understand, making the Semantic Web a \" web of data \".\n",
            "2. What does semantic web mean?\n",
            "Let's separate the word. So first, what does semantics mean? To be specific, the word semantic\n",
            "means relating to meaning in language or logic .\n",
            "And we all know what does web mean right?. Web is short for World Wide Web. The World\n",
            "Wide Web is a network of online content that is accessible through the Internet\n",
            "---\n",
            " It includes\n",
            "websites, webpages, and other online resources.\n",
            "So combining these two’s we will be able to create a meaningful, insightful, data-driven web for\n",
            "the people.\n",
            "2. Why do we go for semantic web?\n",
            "There are a few reasons for why we might go for a semantic web. One reason is that it can help\n",
            "machines to better understand the data that is on the web, which can make it easier for them to\n",
            "find the information that we are looking for\n",
            "---\n",
            " Additionally, a semantic web can help to improve\n",
            "the way that search engines work, as they will be able to better understand the relationships\n",
            "between different pieces of information. Finally, it can make it easier for people to find the\n",
            "information they are looking for, as the semantic web can provide a way to organize information\n",
            "in a more logical way.\n",
            "13\n",
            "---\n",
            " Semantic web stack\n",
            "The Semantic Web stack includes standards for:\n",
            "- Interlinking data (URI, RDF, OWL)\n",
            "- Describing data (RDFS, OWL)\n",
            "- Query languages (SPARQL)\n",
            "- Serialization formats (RDF/XML, Turtle, JSON-LD)\n",
            "The Semantic Web is a stack of technologies that enables machines to understand the meaning of\n",
            "data on the web.\n",
            "- RDF : A data model for representing information as a graph of interconnected resources.\n",
            "- RDFS : A language for describing the types of resources in an RDF graph\n",
            "---\n",
            "\n",
            "- OWL : A language for expressing more complex relationships b/w resources in an RDF graph.\n",
            "- SPARQL : A query language for retrieving information from an RDF graph.\n",
            "Fig 1.1 Semantic web stack - user:Marobi1, CC0, via Wikimedia Commons\n",
            "4. Challenges\n",
            "There are a number of challenges associated with implementing the Semantic Web, including:\n",
            "21\n",
            "---\n",
            " Ensuring data quality and consistency : One of the challenges with implementing the\n",
            "Semantic Web is ensuring that the data being used is of high quality and is consistent across\n",
            "different sources. This can be a challenge because it requires organizations to agree on standards\n",
            "for how data should be structured and formatted.\n",
            "2. Interoperability : Another challenge with implementing the Semantic Web is ensuring\n",
            "interoperability between different systems\n",
            "---\n",
            " This can be a challenge because different systems\n",
            "may use different standards for how data is structured and formatted.\n",
            "3. Scalability : A third challenge with implementing the Semantic Web is ensuring that the\n",
            "system can scale to handle large amounts of data. This can be a challenge because the Semantic\n",
            "Web relies on ontologies, which can become very large and complex as the amount of data\n",
            "increases.\n",
            "4\n",
            "---\n",
            " Security and Privacy : A fourth challenge with implementing the Semantic Web is ensuring\n",
            "security and privacy. This can be a challenge because the Semantic Web relies on sharing data\n",
            "between different organizations, which can put sensitive information at risk.\n",
            "5. Cost : A final challenge with implementing the Semantic Web is the cost. This can be a\n",
            "challenge because the Semantic Web requires organizations to invest in new hardware and\n",
            "software, and to train staff on how to use the new system\n",
            "---\n",
            "\n",
            "5. Use cases of semantic web\n",
            "The goal of the Semantic Web is to make data on the web more machine-readable and easier to\n",
            "process. This enables new applications that can make use of this data, such as:\n",
            "- Automated data processing\n",
            "- Intelligent search\n",
            "- Personalized content\n",
            "- Semantic analytics\n",
            "The Semantic Web can be used for a variety of tasks, including:\n",
            "1. Finding and sharing information :\n",
            "3The Semantic Web can help you find the information you need, and also share the information\n",
            "you have\n",
            "---\n",
            "\n",
            "2. Connecting people and devices :\n",
            "The Semantic Web can connect people and devices, so that they can work together.\n",
            "3. Automating tasks :\n",
            "The Semantic Web can automate tasks, so that you can do more with less effort.\n",
            "4. Enhancing security :\n",
            "The Semantic Web can help to enhance security, by making it easier to identify and trust the\n",
            "sources of information.\n",
            "6. Researches\n",
            "Semantic Web can help to enhance security, by making it easier to identify and trust the sources\n",
            "of information\n",
            "---\n",
            " The ACACIA team of INRIA-Sophia-Antipolis, established in 2002, was the\n",
            "first research organization specifically devoted to the Corporate Semantic Web. The Corese\n",
            "search engine, which is RDF(S) based, is a result of their work, as is the use of semantic web\n",
            "technologies for knowledge management (such as ontologies and multi-agent systems for\n",
            "corporate semantic Web) and e-learning\n",
            "---\n",
            "\n",
            "The Free University of Berlin's Corporate Semantic Web research group has been concentrating\n",
            "on three building blocks since 2008: Corporate Semantic Search, Corporate Semantic\n",
            "Collaboration, and Corporate Ontology Engineering.\n",
            "The issue of how to integrate non-expert users in the creation of ontologies and semantically\n",
            "annotated content and for extracting explicit knowledge from user interaction within companies\n",
            "is one that is covered by ontology engineering research.\n",
            "7\n",
            "---\n",
            " CONCLUSION\n",
            "The Semantic Web is not a single technology or application. It is a collection of standards that\n",
            "can be used together to create data-driven applications. The Semantic Web is an important\n",
            "4concept that can help make information on the Internet more accessible and easier to use. By\n",
            "using Semantic Web technologies, information can be better organized and presented in a way\n",
            "that is easier for people to find and use.\n",
            "8. References\n",
            "1. Semantic Web ↗\n",
            "2\n",
            "---\n",
            " Semantic Web: A Review Of The Field ↗\n",
            "3. A semantic web technology index ↗\n",
            "5\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client.http.models import PointStruct\n",
        "\n",
        "points = []\n",
        "i = 1\n",
        "for chunk in chunks:\n",
        "  i+=1\n",
        "\n",
        "  print(\"Embeddings chunk: \", chunk)\n",
        "  response = openai.Embedding.create(\n",
        "      input=chunk,\n",
        "      model=\"text-embedding-ada-002\"\n",
        "  )\n",
        "  embeddings = response['data'][0]['embedding']\n",
        "  points.append(PointStruct(id=1, vector=embeddings, payload={\"text\": chunk}))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUZ8XtgOe-EG",
        "outputId": "f93bf411-28e1-466e-8943-d3d2e10a46e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings chunk:  Semantic web\n",
            "1. Introduction\n",
            "The Semantic Web is an extension of the World Wide Web through standards by the World\n",
            "Wide Web Consortium (W3C). Semantic Web standards enable the next generation of online\n",
            "data, giving users more control over how data is displayed and processed.\n",
            "The Semantic Web is built on the idea that computers can understand the meaning of information\n",
            "on the web (semantics) as well as the traditional meaning of structured data, like databases\n",
            "Embeddings chunk:   This\n",
            "enables computers to automatically process and combine data in ways that humans can\n",
            "understand, making the Semantic Web a \" web of data \".\n",
            "2. What does semantic web mean?\n",
            "Let's separate the word. So first, what does semantics mean? To be specific, the word semantic\n",
            "means relating to meaning in language or logic .\n",
            "And we all know what does web mean right?. Web is short for World Wide Web. The World\n",
            "Wide Web is a network of online content that is accessible through the Internet\n",
            "Embeddings chunk:   It includes\n",
            "websites, webpages, and other online resources.\n",
            "So combining these two’s we will be able to create a meaningful, insightful, data-driven web for\n",
            "the people.\n",
            "2. Why do we go for semantic web?\n",
            "There are a few reasons for why we might go for a semantic web. One reason is that it can help\n",
            "machines to better understand the data that is on the web, which can make it easier for them to\n",
            "find the information that we are looking for\n",
            "Embeddings chunk:   Additionally, a semantic web can help to improve\n",
            "the way that search engines work, as they will be able to better understand the relationships\n",
            "between different pieces of information. Finally, it can make it easier for people to find the\n",
            "information they are looking for, as the semantic web can provide a way to organize information\n",
            "in a more logical way.\n",
            "13\n",
            "Embeddings chunk:   Semantic web stack\n",
            "The Semantic Web stack includes standards for:\n",
            "- Interlinking data (URI, RDF, OWL)\n",
            "- Describing data (RDFS, OWL)\n",
            "- Query languages (SPARQL)\n",
            "- Serialization formats (RDF/XML, Turtle, JSON-LD)\n",
            "The Semantic Web is a stack of technologies that enables machines to understand the meaning of\n",
            "data on the web.\n",
            "- RDF : A data model for representing information as a graph of interconnected resources.\n",
            "- RDFS : A language for describing the types of resources in an RDF graph\n",
            "Embeddings chunk:  \n",
            "- OWL : A language for expressing more complex relationships b/w resources in an RDF graph.\n",
            "- SPARQL : A query language for retrieving information from an RDF graph.\n",
            "Fig 1.1 Semantic web stack - user:Marobi1, CC0, via Wikimedia Commons\n",
            "4. Challenges\n",
            "There are a number of challenges associated with implementing the Semantic Web, including:\n",
            "21\n",
            "Embeddings chunk:   Ensuring data quality and consistency : One of the challenges with implementing the\n",
            "Semantic Web is ensuring that the data being used is of high quality and is consistent across\n",
            "different sources. This can be a challenge because it requires organizations to agree on standards\n",
            "for how data should be structured and formatted.\n",
            "2. Interoperability : Another challenge with implementing the Semantic Web is ensuring\n",
            "interoperability between different systems\n",
            "Embeddings chunk:   This can be a challenge because different systems\n",
            "may use different standards for how data is structured and formatted.\n",
            "3. Scalability : A third challenge with implementing the Semantic Web is ensuring that the\n",
            "system can scale to handle large amounts of data. This can be a challenge because the Semantic\n",
            "Web relies on ontologies, which can become very large and complex as the amount of data\n",
            "increases.\n",
            "4\n",
            "Embeddings chunk:   Security and Privacy : A fourth challenge with implementing the Semantic Web is ensuring\n",
            "security and privacy. This can be a challenge because the Semantic Web relies on sharing data\n",
            "between different organizations, which can put sensitive information at risk.\n",
            "5. Cost : A final challenge with implementing the Semantic Web is the cost. This can be a\n",
            "challenge because the Semantic Web requires organizations to invest in new hardware and\n",
            "software, and to train staff on how to use the new system\n",
            "Embeddings chunk:  \n",
            "5. Use cases of semantic web\n",
            "The goal of the Semantic Web is to make data on the web more machine-readable and easier to\n",
            "process. This enables new applications that can make use of this data, such as:\n",
            "- Automated data processing\n",
            "- Intelligent search\n",
            "- Personalized content\n",
            "- Semantic analytics\n",
            "The Semantic Web can be used for a variety of tasks, including:\n",
            "1. Finding and sharing information :\n",
            "3The Semantic Web can help you find the information you need, and also share the information\n",
            "you have\n",
            "Embeddings chunk:  \n",
            "2. Connecting people and devices :\n",
            "The Semantic Web can connect people and devices, so that they can work together.\n",
            "3. Automating tasks :\n",
            "The Semantic Web can automate tasks, so that you can do more with less effort.\n",
            "4. Enhancing security :\n",
            "The Semantic Web can help to enhance security, by making it easier to identify and trust the\n",
            "sources of information.\n",
            "6. Researches\n",
            "Semantic Web can help to enhance security, by making it easier to identify and trust the sources\n",
            "of information\n",
            "Embeddings chunk:   The ACACIA team of INRIA-Sophia-Antipolis, established in 2002, was the\n",
            "first research organization specifically devoted to the Corporate Semantic Web. The Corese\n",
            "search engine, which is RDF(S) based, is a result of their work, as is the use of semantic web\n",
            "technologies for knowledge management (such as ontologies and multi-agent systems for\n",
            "corporate semantic Web) and e-learning\n",
            "Embeddings chunk:  \n",
            "The Free University of Berlin's Corporate Semantic Web research group has been concentrating\n",
            "on three building blocks since 2008: Corporate Semantic Search, Corporate Semantic\n",
            "Collaboration, and Corporate Ontology Engineering.\n",
            "The issue of how to integrate non-expert users in the creation of ontologies and semantically\n",
            "annotated content and for extracting explicit knowledge from user interaction within companies\n",
            "is one that is covered by ontology engineering research.\n",
            "7\n",
            "Embeddings chunk:   CONCLUSION\n",
            "The Semantic Web is not a single technology or application. It is a collection of standards that\n",
            "can be used together to create data-driven applications. The Semantic Web is an important\n",
            "4concept that can help make information on the Internet more accessible and easier to use. By\n",
            "using Semantic Web technologies, information can be better organized and presented in a way\n",
            "that is easier for people to find and use.\n",
            "8. References\n",
            "1. Semantic Web ↗\n",
            "2\n",
            "Embeddings chunk:   Semantic Web: A Review Of The Field ↗\n",
            "3. A semantic web technology index ↗\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "operation_info = qdrant_client.upsert(\n",
        "    collection_name=\"mycollection\",\n",
        "    wait=True,\n",
        "    points=points\n",
        ")\n",
        "\n",
        "print(\"Operation info:\", operation_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8tdBSk0e2L3",
        "outputId": "c7788e44-4193-44f8-8e29-45e0cde33767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation info: operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_answer_with_context(query):\n",
        "  response=openai.Embedding.create(\n",
        "      input=\"What is semantic web?\",\n",
        "      model = \"text-embedding-ada-002\"\n",
        "  )\n",
        "  embeddings = response['data'][0]['embedding']\n",
        "  search_result = qdrant_client.search(\n",
        "      collection_name='mycollection',\n",
        "      query_vector=embeddings,\n",
        "      limit = 5\n",
        "  )\n",
        "  prompt= \"Context:\\n\"\n",
        "  for result in search_result:\n",
        "    prompt += result.payload['text'] + \"\\n---\\n\"\n",
        "  prompt += \"Questions:\" + query + \"\\n---\\n\" + \"Answer:\"\n",
        "\n",
        "  print(\"----PROMPT START----\")\n",
        "  print(\":\", prompt)\n",
        "  print(\"---PROMPT END----\")\n",
        "\n",
        "  completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "HjZU5welfuHO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"What is semantic web?\"\n",
        "answer = create_answer_with_context(input)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwsplbTChFOM",
        "outputId": "dfc3563a-fb11-4d3e-f9be-7a8cd2475980"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----PROMPT START----\n",
            ": Context:\n",
            " Finally, it can make it easier for people to find the\n",
            "1\n",
            "---\n",
            "Questions:What is semantic web?\n",
            "---\n",
            "Answer:\n",
            "---PROMPT END----\n",
            "The context provided does not fully explain what semantic web is, but it suggests that it is a technology that improves the way people can find things online. \n",
            "\n",
            "Semantic web is a concept in web technology that aims to make web pages and data machine-readable, enabling computers to understand the meaning of the content and create connections between different pieces of information. It involves the use of metadata, or data about data, to describe the relationships between different resources on the web. This makes it easier for people to access and use information from a variety of sources, regardless of the format, language, or platform used.\n"
          ]
        }
      ]
    }
  ]
}